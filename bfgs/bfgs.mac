defstruct(
  bfgs_input(
    func,
    grad,
    /* A column vector.*/
    init,
    eps,
    max_times))$

defstruct(
  bfgs_output(
    value,
    times,
    estimate,
    gradient,
    hessian))$

bfgs_norm(vector):=float(sqrt(sum(vector[i,1]^2,i,1,length(vector))))$

bfgs_linear_search_wolfe_condition(func,grad,X,dir,c1,c2,inc,dec,init):=block(
  [alpha,newX,condition,left,right,count],
  print("linear search wolfe condition"),
  count:0,
  alpha:init,
  condition:false,
  if not is(0.0 < c1 and c1 < c2 and c2 < 1.0) then
  error("invalid parameters [c1 c2]."),
  unless condition do block(
    print("Wolfe Linear Search Count:",count:count+1),
    if is(alpha = 0.0) then error("error alpha value."),
    newX : X + alpha . dir,
    left : float(func(newX)),
    right : float(func(X) + c1 . alpha . (grad(X) . dir)),
    print("First compare,newX=",nexX," left=",left," right=",right),
    condition : not is(left > right),
    if condition then block(
      left : float(grad(newX) . dir),
      right : float(c2 . grad(X) . dir),
      print("First compare,newX=",nexX," left=",left," right=",right),
      condition : not abs(left) > abs(right),
      print("Wolfe Linear Search alpha=",alpha),
      if not condition then alpha : float(alpha * inc))
    else alpha : float(alpha * dec)),
  float(alpha))$

bfgs_optimize(bfgs):=block(
  [alpha,times,Br,X1,X2,dX1,dX2,old,value,Grad,P,S,Y,t1,t2,t3,t4,t5,t6,t7,t8],
  local(Brf),
  Brf[i,j] := if i=j then 1.0 else 0.0,
  Br:genmatrix(Brf,length(bfgs@init),length(bfgs@init)),
  print("Br",Br),
  X1 : bfgs@init,
  value : bfgs@func(bfgs@init),
  old:value + bfgs@eps * 2,
  times:0,
  print("Before running into the main loop."),
  unless times > bfgs@max_times or abs(old - value) < bfgs@eps do block(
    old:value,
    times:times+1,
    print("Starting loop:",times,"..."),
    Grad : bfgs@grad(X1),
    print("Gradient at",X1," is ",Grad),
    P : Br . (-1.0 . Grad),
    print("P ",Grad),
    print("P Norm ",bfgs_norm(P)),
    if is(bfgs_norm(P) < bfgs@eps) then return,
    alpha : 1 / bfgs_norm(P),
    print("Initial alpha=",alpha),
    alpha : bfgs_linear_search_wolfe_condition(
      bfgs@func,
      bfgs@grad,
      X1,
      P,
      0.0001,
      0.9,
      1.1,
      0.5,
      alpha),
    print("Wolfe Condition alpha=",alpha),
    S : alpha * P,
    X2 : X1 + S,
    dX1 : bfgs@grad(X1),
    dX2 : bfgs@grad(X2),
    Y : dX2 - dX1,
    t1 : transpose(S) . Y,
    t2 : transpose(Y) . Br . Y,
    t3 : S . transpose(S),
    t4 : (t1 + t2) * t3,
    t5 : (transpose(Y) . S) ^ 2,
    t6 : Br . Y . transpose(S),
    t7 : S . transpose(Y) . Br,
    t8 : transpose(S) . Y,
    Br : Br + t4 / t5 - (t6 + t7) / t8,
    X1 : X2,
    print("Starting loop:",times," done."),
    value : bfgs@func(X1),
    print("Old=",old,",New=",value)),
  new(
    bfgs_output(
      value:value,
      times:times,
      estimate:X1,
      gradient:Grad,
      hessian:Br)))$